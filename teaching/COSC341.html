<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<title>COSC341 Theory of Computing - Alex Gavryushkin</title>
	<meta name="author" content="Alex Gavryushkin">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
	<meta name="apple-mobile-web-app-capable" content="yes" />
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
	<link rel="stylesheet" href="../talks/css/reveal.css">
	<link rel="stylesheet" href="../talks/css/theme/simple_gavruskin.css" id="theme">
	<link rel="stylesheet" href="../talks/lib/css/zenburn.css">
	<link rel="icon" href="../favicon.ico" />
	<!--[if lt IE 9]>
	<script src="../talks/lib/js/html5shiv.js"></script>
	<![endif]-->
</head>

<body>
<div class="reveal">
<div class="slides">

<section>
	<h4>
	  COSC341
	</h4>
	<h3>
	  Theory of Computing
	</h3>
	<br>
	<h4>
	  Alex Gavryushkin<br>
	  <br>
	  <img data-src="../talks/images/otago_university_logo.svg" width=30%>
	</h4>
	<br>
	<font size="5">
	  2019 Semester 1<br>
	</font>
</section>

<section>
<section>
	<h3>Table of contents</h3>

	<ul>
	  <li> <a href="#/L1">Lecture 1: Introduction</a>
	  <li> <a href="#/L2">Lecture 2: Sets, relations, functions</a>
	  <li> <a href="#/L3">Lecture 3: Cardinality</a>
	  <li> <a href="#/L4">Lecture 4: Finite state automata</a>
	  <li> <a href="#/L5">Lecture 5: Non-deterministic automata</a>
	  <li> <a href="#/L6">Lecture 6: NFA = DFA</a>
	  <li> <a href="#/L7">Lecture 7: Pumping lemma</a>
	  <li> <a href="#/L8">Lecture 8: Pushdown automata and context free grammars</a>
	  <li> <a href="#/L9">Lecture 9: Regular languages</a>
	  <li> <a href="#/L10">Lecture 10: Classification of languages, pumping Lemma 2</a>
	  <li> <a href="#/L11">Lecture 11: Turing Machines</a>
	  <li> <a href="#/L12">Lecture 12: Turing Machines</a>
	  <li> <a href="#/L13">Lecture 13: Turing Machines</a>
	</ul>
</section>

  <section>
	<h3>Handouts</h3>
	<ul>
	  <li> <a href="COSC341">These slides</a>
	  <li> <a href="cosc341_lecture_notes_part1.pdf">Complementary lecture notes</a><br><br>
	</ul>

	<h3>
	  Information
	</h3>
	<ul>
	  <li> <a href="http://www.cs.otago.ac.nz/cosc341/">COSC341 website</a>
	  <li> Assessment
		<ul>
		  <li> Assignment 1: 10% due Thursday <b>28 March</b>
		  <li> Assignment 2: 10% due Friday <b>29 April</b>
		  <li> Assignment 3: 10% due Friday <b>24 May</b>
		  <li> Final exam: 70% on <b>TBA</b>
		</ul>
	</ul>
  </section>

  <section>
	<h3><a href="https://biods.org/alex">Lecturer</a></h3>
	<img data-src="images/bioDS_lab_2019_COSC341.svg">
	GitHub: <a href="https://github.com/bioDS">@bioDS</a><br><br>
	Twitter: <a href="https://twitter.com/bioDS_lab">@bioDS_lab</a>
  </section>
</section>

<section id="L1">
	<h2>Lecture 1</h2>
	<h2>Introduction</h2>
</section>

<section>
	<h4>
	  Who cares about theory of computing?<br>
	  I do!
	</h4>
	<img class="stretch" data-src="images/DS_diagramme.svg"><br>
	<p style="font-size:13pt">
	  ML = Machine Learning<br>
	  CoSt = Computational Statistics<br>
	  AS = Applied Statistics
	</p>
</section>

<section>
	<h4>
	  Who cares about theory of computing?<br>
	  You do!
	</h4>
	<img class="stretch" data-src="images/why_ToC.svg"><br>
	<p style="font-size:11pt">
	  Garey and Johnson. <i>Computers and Intractability.</i>
	</p>
</section>

<section>
	<h3>
	  Why biological data science?
	</h3>
	<p class="fragment" data-fragment-index="1">
	  Because the skills are highly transferable:
	  <ul>
	    <li class="fragment" data-fragment-index="1"> Nosy data
	    <li class="fragment" data-fragment-index="2"> Visualisation
	    <li class="fragment" data-fragment-index="3"> Communication
	    <li class="fragment" data-fragment-index="4"> High-performance computing
	  <ul>
	</p>
</section>

<section>
	<h3>
	  Why is it suddenly a thing?
	</h3>
	<img class="stretch" data-src="images/costpergenome_2017.jpg">
</section>

<section>
	<h3>Sets</h3>
	A set is a collection of objects, completely determined by the objects.
	Two sets are equal if they contain the same objects.<br><br>

	$X = \{1, 2, 5\} = \{2, 5, 1\} = \{5, 2, 1, 5, 1\}$<br><br>
	$X = \{x \mid P(x)\}$, where $P(x)$ is a logical condition on $x$.<br><br>
	$\mathbb N = \{0, 1, \ldots \}$<br><br>
	$X = \{x \mid (\exists y \in \mathbb N) x = y^2\} \stackrel{?}{=} \{x \mid x = y^2\}$<br><br>
	$9 \in X?$
</section>

<section>
	<h2>Empty set<br>
	$\varnothing$<br>
	is a set!</h2>
	You will forget this. Yes, you.<br><br>
</section>

<section>
	<h4>Operations on sets</h4>
	<img class="stretch" data-src="images/DS_diagramme.svg"><br>
	<p style="font-size:13pt">
	  ML = Data $\cap$ Algorithms<br><br>
	  (Statistics$\setminus$DS) $\cap$ Algorithms $\neq \varnothing$<br><br>
	  $\overline{\mbox{Data} \cup \mbox{Algorithms} \cup \mbox{Statistics}} = ?$
	</p>
</section>

<section id="L2">
	<h2>Lecture 2</h2>
	<h2>Sets, relations, functions</h2>
</section>

<section>
	<h4>Subsets, ordered tuples, relations, and functions</h4>
	<p>
	  $A \subseteq B \iff (\forall x) (x \in A \Rightarrow x \in B)$<br><br>
	</p>

	<p class="fragment" data-fragment-index="1">
	  $\mathcal P(A) = \{X \mid X \subseteq A\}$<br><br>
	</p>

	<p class="fragment" data-fragment-index="2">
	  $(a, b) = (c, d) \iff (a = c~\&~b = d)$<br><br>
	</p>

	<p class="fragment" data-fragment-index="3">
	  $A \times B = \{(a, b) \mid a \in A, b \in B\}$<br><br>
	</p>

	<p class="fragment" data-fragment-index="4">
	  $P \subseteq A \times B$ is a <b>relation</b> (from $A$ to $B$, or <b>on</b> $A$ if $A = B$)<br><br>
	</p>

	<p class="fragment" data-fragment-index="5">
	  $f \subseteq A \times B$ is a <b>function</b> if $(f(a) = b ~\&~ f(a) = c) \Rightarrow b = c$
	</p>
</section>

<section>
	<h3>Types of functions</h3><br><br>
	Let $f : A \to B$.
	The function $f$ is called<br><br>
	<p>
	  <b>injective</b> if $f(a) = f(b) \Rightarrow a = b$<br><br>
	</p>

	<p class="fragment" data-fragment-index="1">
	  <b>surjective</b> if $(\forall y \in B)(\exists x \in A)f(x) = y$<br><br>
	</p>

	<p class="fragment" data-fragment-index="2">
	  <b>bijective</b> if $f$ is injective and surjective.
	</p>
</section>

<section>
	<h4>
	  Molecular biology: crash course
	</h4>
	<img class="stretch" data-src="images/central_dogma.svg">
</section>

<section data-background-video="http://content.dnalc.org/content/c16/16933/3d-central-dogma-audio-title.mp4">
</section>

<section>
	<h3>
	  Classical genetics
	</h3>
	<img class="stretch" data-src="images/classic_genetics.svg">
</section>

<section>
	<h3>
	  Modern genomics
	</h3>
	<img class="stretch" data-src="images/modern_genomics.svg">
</section>

<section>
	<h3>
	  Reality
	</h3>
	<img class="stretch" data-src="images/GWAS_diagramme.svg">
</section>

<section>
	<h3>Partitions and equivalence relations</h3><br><br>
	<p>
	$A = B \sqcup C$ is a <b>partition</b> if $A = B \cup C$ and $B \cap C = \varnothing$<br><br>
	</p>

	<p class="fragment" data-fragment-index="1">
	  A relation $\sim$ on $A$ is called an <b>equivalence relations</b> if $\sim$ is:<br>
	  <ul class="fragment" data-fragment-index="1">
	    <li> <b>Reflexive</b> $(\forall x \in A)~x \sim x$
	    <li> <b>Symmetric</b> $(\forall x, y \in A)~(x \sim y \Rightarrow y \sim x)$
	    <li> <b>Transitive</b> $(\forall x, y, z \in A)~(x \sim y ~\&~ y \sim z \Rightarrow x \sim z)$
	  </ul>
	</p>
</section>

<section>
	<h3>Theorem 1</h3>
	A partition of a set $A$ is the same thing as an equivalence relation on $A$.<br><br>

	<i>In other words:</i> Let $A$ be a set. Then
	<ol>
	  <li> A partition $A_1 \sqcup A_2 \sqcup \ldots$ of the set $A$ is defined by an equivalence relation on $A$.
	  <li> An equivalence relation $\sim$ on the set $A$ defines a partition on $A$.
	</ol>
	<b>Proof:</b> Exercise for those who skipped the lecture.
</section>

<section id="L3">
	<h2>Lecture 3</h2>
	<h2>Cardinality</h2>
</section>

<section>
	Two sets $A$ and $B$ <b>have the same cardinality</b> if there exists a bijection $f : A \to B$, written $|A| = |B|$.<br><br>
	<p class="fragment" data-fragment-index="1">
	  Set $A$ has <b>smaller cardinality</b> than $B$ if there exists a (total) injection $f : A \to B$, written $|A| \leqslant |B|$.<br><br>
	</p>

	<p class="fragment" data-fragment-index="2">
	  <b>Theorem:</b> $|A| = |B| \iff (|A| \leqslant |B| ~\&~ |B| \leqslant |A|)$.<br><br>
	</p>

	<p class="fragment" data-fragment-index="3">
	  $|\mathbb N| \stackrel{?}{=} |\mathbb Z| \stackrel{?}{=} |\mathbb Q| \stackrel{?}{=} |\mathbb R|$
	</p>
</section>

<section>
	<h3>Theorem 2</h3>
	$|\mathbb N| < |\mathbb R|$
</section>

<section id="L4">
	<h2>Lecture 4</h2>
	<h2>Finite state automata</h2>
</section>

<section>
	<img data-src="images/FSA1.png">
</section>

<section>
	<img data-src="images/FSA2.png">
</section>

<section>
	<img data-src="images/FSA3.png">
</section>

<section>
	<h4>DFA</h4>
	<img data-src="images/FSA3.png"><br>
	A <b>deterministic finite state automaton</b>, $M$, consists of:
	<ul>
	  <li> A finite set, $Q$, of <b>states</b>
	  <li> A finite set $\Sigma$ called the <b>alphabet</b>
	  <li> A total function $\delta: Q \times \Sigma \to Q$ called the <b>transition function</b>
	  <li> A distinguished state $q_0 \in Q$ called the <b>initial state</b>
	  <li> A subset $F \subseteq Q$ called the <b>final</b> or <b>accepting states</b>.
	</ul>
</section>

<section>
	<img data-src="images/FSA3.png"><br>
	Given a word $w = w_0 w_1 \dots w_{n-1} \in \Sigma^*$ the <b>computation</b> carried out by $M$ on input $w$ is a sequence of states $q_0, q_1, q_2, \dots, q_n$ defined as follows:
	\[
	  q_1 = \delta(q_0, w_0), \: q_2 = \delta(q_1, w_1), \: \dots ,\: q_n = \delta(q_{n-1}, w_{n-1})
	\]
	<p class="fragment" data-fragment-index="1">
	  We say that $M$ <b>accepts</b> or <b>recognises</b> $w$ if $q_n \in F$ and otherwise it <b>rejects</b> $w$.<br><br>

	  The <b>language of $M$</b>, $L(M)$ is just the set of strings in $\Sigma^*$ that $M$ accepts.
	</p>
</section>

<section id="L5">
	<h2>Lecture 5</h2>
	<h2>Non-deterministic automata</h2>
</section>

<section>
	<h3>NFA</h3>
	Relax the definition of the transition function to become a <b>transition relation</b>.
	\[
	  \delta \subseteq Q \times \Sigma \cup \{\lambda\} \times Q
	\]<br>
	<img class="fragment" data-fragment-index="1" data-src="images/FSA3.png">
	<p class="fragment" data-fragment-index="2" >
	  $\{ab\}$ in English alphabet
	</p>
</section>

<section>
	<h3>Examples</h3>
	<p>
	  Design an automaton that recognises the following languages in alphabet $\{a,b\}$
	</p>

	<p class="fragment" data-fragment-index="1">
	  $L_1 = \{w | w = xaaybbbz, \mbox{ where } x,y,z \in\{a,b\}^*\}$
	</p>

	<p class="fragment" data-fragment-index="2">
	  $L_2 = \{w | w \mbox{ contains $aa$ or $bbb$}\}$
	</p>

	<p class="fragment" data-fragment-index="3">
	  $L_3 = \{w | w \mbox{ contains $aa$ and $bbb$}\}$
	</p>
</section>

<section id="L6">
	<h2>Lecture 6</h2>
	<h2>NFA = DFA, pumping lemma</h2>
</section>

<section>
	<h3>Theorem 3</h3>
	The classes of languages recognised by DFA and NFA coincide.
</section>

<section>
	<img class="stretch" data-src="images/NFA_to_make_DFA.png">
</section>

<section>
	  $L = \{w \in\{a, b\}^* \mid w \mbox{ contains $abba$ or $aa$}\}$
</section>

<section>
	<h3>Theorem 3</h3>
	The classes of languages recognised by DFA and NFA coincide.<br><br>
	<b>Proof:</b> Go to the lecture (or read in the notes).
</section>

<section id="L7">
	<h2>Lecture 7</h2>
	<h2>Pumping lemma</h2>
</section>

<section>
	$L = \{a^nb^n \mid n \in \mathbb{N}\}$<br><br>
	<h4 class="fragment" data-fragment-index="1"><b>Pumping lemma</b></h4>
	<p class="fragment" data-fragment-index="1">
	  Let $L$ be an automatic language.
	  Then there exists a positive integer $k$ such that if $z \in L$, $|z| \geq k$ then for some $u$, $v$, and $w$:<br>
	$
	  \begin{eqnarray*}
	    z &=& u \cdot v \cdot w \\
	    |u| + |v| &\leq& k \\
	    |v| &>& 0 \\
	    uv^iw &\in& L \quad \mbox{for all $i \geq 0$}.
	  \end{eqnarray*}
	$
	</p>
	<p class="fragment" data-fragment-index="2">
	  <b>Proof:</b> Haven't we just proven it?
	</p>
	<p class="fragment" data-fragment-index="3">
	  $L = \{w \in \{a, b\} \mid \mbox{$w$ contains an odd number of $a$'s}$<br>
	  $\mbox{and an even number of $b$'s}\}$
	</p>
</section>

<section id="L8">
	<h2>Lecture 8</h2>
	<h2>Pushdown automata and context free grammars</h2>
</section>

<section>
	A <b>pushdown automaton</b>, $M$, consists of:
	<ul>
	  <li> A finite set $Q$ of <b>states</b>
	  <li> A finite set $\Sigma$ called the <b>input alphabet</b> (lower case letters)
	  <li> A finite set $\color{blue}{\Gamma}$ called the <b>stack alphabet</b> (upper case letters)
	  <li> A relation $\delta \subseteq Q \times \Sigma \cup \{\lambda\} \times \color{blue}{\Gamma \cup \{\lambda\}} \times Q \times \color{blue}{\Gamma \cup \{\lambda\}}$<br>
		called the <b>transition relation</b>
	  <li> A distinguished state $q_0 \in Q$ called the <b>initial state</b>
	  <li> A subset $F \subseteq Q$ called the <b>final</b> or <b>accepting states</b>.
	</ul>

	<p class="fragment" data-fragment-index="1">
	  <b>The stack should be empty to accept a string!</b>
	</p>
	<img class="fragment" data-fragment-index="2" data-src="images/PDA.png" width="50%">
</section>

<section>
	A <b>context-free grammar</b>, $G$, consists of:
	<ul>
	  <li> A finite set $V$ of <b>nonterminals</b> (or variables)<br>
		(upper case letters)
	  <li> A finite set $\Sigma$ called the <b>alphabet</b> (or terminals)<br>
		(lower case letters), $\Sigma \cap V = \varnothing$
	  <li> A finite set $P$ of <b>production rules</b>,<br>
		which is a subset of $V \times (V \cup \Sigma)^*$
	  <li> A distinguished $S \in V$ called the <b>start symbol</b>
	</ul>

	<p class="fragment" data-fragment-index="1">
	  <b>Examples</b><br>
	  $S \to aS, S \to bS, S \to \lambda$
	</p>

	<p class="fragment" data-fragment-index="2">
	  $S \to aS, S \to bT, T \to bT, T \to \lambda$
	</p>

	<p class="fragment" data-fragment-index="3">
	  $\{a^nb^n \mid n \in \mathbb{N}\}$
	</p>
</section>

<section>
	<h3>Theorem</h3>
	$\mathcal L_{PDA} = \mathcal L_{CFG}$
</section>

<section data-background="images/human_male_karyotype.svg" data-background-size="900px">
</section>

<section>
	<h3>Genome phasing</h3>
	<img class="stretch" data-src="images/NFA_Schwartz.svg">
	<p style="font-size:9pt">
	Schwarz, Roland F., Anne Trinh, Botond Sipos, James D. Brenton, Nick Goldman, and Florian Markowetz. 2014. “Phylogenetic Quantification of Intra-Tumour Heterogeneity.” <i>PLoS Computational Biology</i> 10 (4): e1003535.<br>
</section>

<section>
	<img data-src="images/CFG_Schwartz.png">
	<p style="font-size:9pt">
	Schwarz, Roland F., Anne Trinh, Botond Sipos, James D. Brenton, Nick Goldman, and Florian Markowetz. 2014. “Phylogenetic Quantification of Intra-Tumour Heterogeneity.” <i>PLoS Computational Biology</i> 10 (4): e1003535.<br>
</section>

<section id="L9">
	<h2>Lecture 9</h2>
	<h2>Regular languages</h2>
</section>

<section>
	The following are <b>regular expressions</b> over the alphabet $\Sigma$:<br>
	$\varnothing$; $\lambda$; $x$ for every $x \in \Sigma$.

	<p class="fragment" data-fragment-index="1">
	  If $\alpha$ and $\beta$ are <b>regular expressions</b> then so are the following:<br>
	  $(\alpha\beta)$; $(\alpha \cup \beta)$; $\alpha^*$
	</p>

	<p class="fragment" data-fragment-index="2">
	  The language $L_\alpha$ <b>described</b> by the regular expression $\alpha$ is defined in the following way:<br>
	  $L_\alpha = \varnothing$ if $\alpha = \varnothing$<br>
	  $L_\alpha = \{\lambda\}$ if $\alpha = \lambda$<br>
	  $L_\alpha = \{x\}$ if $\alpha = x$
	</p>

	<p class="fragment" data-fragment-index="3">
	  $L_{\alpha\beta} = \{uv \mid u \in L_\alpha \mbox{ and } v \in L_\beta\}$<br>
	  $L_{\alpha\cup\beta} = L_\alpha \cup L_\beta$<br>
	  $L_{\alpha^*} = \{w_1 \ldots w_k \mid w_1, \ldots, w_k \in L_\alpha \mbox{ and } k \in \mathbb N\}$<br>
	</p>
</section>

<section>
	<p>
	  Language $L$ is called <b>regular</b> if it can be described by a regular expression $\alpha$, that is, there exists $\alpha$ such that $L = L_\alpha$.
	</p>
	<h3>Examples</h3>
	\begin{align*}
	  L_a		&= a(a \cup b)^*\\
	  \\
	  L_e 		&= ((a \cup b)(a \cup b))^*\\
	  \\
	  L_{bb}	&= (a \cup b)^*bb(a\cup b)^*\\
	  \\
	  L_{2b}	&= a^*ba^*ba^*
\end{align*}
</section>

<section id="L10">
	<h2>Lecture 10</h2>
	<h2>Classification of languages, Pumping Lemma 2</h2>
</section>

<section>
	<b>Theorem (i):</b> $\mathcal L_{DFA} = \mathcal L_{reg}$
	<p class="fragment" data-fragment-index="1">
	  <i>Proof:</i> Easy.
	</p>

	<p class="fragment" data-fragment-index="2">
	  <b>Theorem (ii):</b> Automatic languages are closed under<br>
	  $\cdot$ (concatenation), $\cup$ (union), $\cap$ (intersection),<br>
	  and $\overline{\phantom a}$ complement.
	</p>
	<p class="fragment" data-fragment-index="3">
	  <i>Proof:</i> Even easier.
	</p>

	<p class="fragment" data-fragment-index="4">
	  <b>Theorem (iii):</b> Context-free languages are closed under<br>
	  $\cdot$ (concatenation) and $\cup$ (union),<br>
	  but not $\cap$ (intersection) or $\overline{\phantom a}$ complement.
	</p>
	<p class="fragment" data-fragment-index="5">
	  <i>Proof:</i> Not yet possible &mdash; we need a version of the pumping lemma.
	</p>
</section>

<section>
	<h3>Classification of languages</h3>
	(so far)<br><br><br>
	$\mathcal L_{DFA} = \mathcal L_{NFA} = \mathcal L_{reg} \subset \mathcal L_{PDA} = \mathcal L_{CFG}$
</section>

<section>
	<h3>Pumping Lemma 2</h3>
	  Let $L$ be a context free language. There is a positive integer $k$ such that for all $z \in L$ with $|z| \geq k$ we can write $z = uvwxy$ such that:
	  \[
	    \begin{array}{c}
		|vwx| \leq k \\
		|v| + |x| > 0 \\
		uv^iwx^iy \in L \quad \mbox{for all $i \geq 0$}.
	    \end{array}
	  \]
</section>

<section>
	  <b>Theorem (iii):</b> Context-free languages are closed under<br>
	  $\cdot$ (concatenation) and $\cup$ (union),<br>
	  but not $\cap$ (intersection) or $\overline{\phantom a}$ complement.
	<p class="fragment" data-fragment-index="1">
	  <i>Proof:</i> Super easy now.
	</p>

	<p class="fragment" data-fragment-index="2">
	  <b>Note:</b> However, if $L$ is a context-free language and $R$ a regular language then $L \cap R$ is context-free!
	</p>
</section>

<section id="L11">
	<h2>Lecture 11</h2>
	<h2>Turing Machines</h2>
</section>

<section>
	<h3>Turing machine</h3>

	<iframe width="560" height="315" src="https://www.youtube.com/embed/E3keLeMwfHY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</section>

<section>
	A <b>Turing machine</b>, $M$, consists of:
	<ul>
	  <li> A finite set $\Gamma$ called the <b>alphabet</b>
	  <li> A finite set $Q$ of <b>states</b>
	  <li> A distinguished state $q_0 \in Q$ called the <b>starting state</b>
	  <li> A subset $F \subseteq Q$ of <b>halting states</b>
	  <li> A distinguished symbol $\beta \in \Gamma$ called the <b>blank symbol</b> (or the empty cell)
	  <li> A partial function $F: (Q \setminus F) \times \Gamma \to Q \times \Gamma \times \{L, R, \varnothing\}$<br>
	    called the <b>program</b>
	</ul>

	<p class="fragment" data-fragment-index="1">
	  Turing machines can be used to formalise all kinds of algorithmic problems, including language recognition, generation, etc.<br>
	<img data-src="images/noBS.svg" width="10%">
	</p>
</section>

<section>
	<p>
	  $a^* b^*$
	</p>
	<p class="fragment" data-fragment-index="1">
	  $\{a^n b^n \mid n \in \mathbb N\}$
	</p>
</section>


<section>
	<h3>Danger zone!</h3>
	<h3>We recommend that you don't scroll past this slide.</h3>
</section>

<section>
	<h3>
	  Formalising biology
	</h3>
	<ul>
	  <li> Let $G$ be the set of binary (quaternary in reality) strings of length $n$.
	  <li> Elements of $G$ are called <i>genotypes</i>.
	  <li class="fragment" data-fragment-index="1"> A function $w: G \to \mathbb R^+$ is called a <i>fitness landscape</i>.
	  <li class="fragment" data-fragment-index="1"> For $g \in G$, $w(g)$ is called <i>fitness of the genotype</i> $g$.
	</ul>
	<img data-fragment-index="2" data-src="../talks/images/fitness_shapes_2_loci_BPS_axis.png">
</section>

<section data-markdown id="how-big-is-big">
<script type="text/template">
	### 3. How big is big in biology
	#### The number of possible rankings of all possible genotypes with $n$ genes is?
	|    Genes|       Number of rankings |
	|:-------:|:------------------------:|
	|    2    |          24              |
	|    3    |          40,320          |
	|    4    |  20,922,789,890,000      |
	|    5    |  $2.6 \times 10^{35}$    |
	|    6    |  $1.3 \times 10^{89}$    |
</script>
</section>

<section data-markdown>
<script type="text/template">
	|    Genes|       Number of rankings |
	|:-------:|:------------------------:|
	|    2    |          24              |
	|    3    |          40,320          |
	|    4    |  20,922,789,890,000      |
	|    5    |  $2.6 \times 10^{35}$    |
	|    6    |  $1.3 \times 10^{89}$    |
	<p>
	  The number of "particles in the observable universe" is estimated between $10^{78}$ and $10^{81}$.
	</p>
	<p class="fragment" data-fragment-index="1">
	  Our genome has over 20,000 protein-coding genes, which is $<2\%$ of the whole genome.
	  The total number of base pairs is over 3,000,000,000, with over 150,000,000 variants.
	</p>
</script>
</section>

<section id="scalability">
	<h3>
	  Scalability<font class="fragment" data-fragment-index="1">: synthetic lethal pairs</font>
	</h3>
	<img class="fragment" data-fragment-index="1" data-src="../talks/images/synthetic_lethality_grey.svg">
	<h3 class="fragment" data-fragment-index="1">
	  How many pairs of genes are there in the human genome?
	</h3>
</section>

<section>
	<h3>
	  Gene-gene interactions
	</h3>
	<img data-src="../talks/images/fitness_shapes_2_loci_BPS_axis.png">
	<h3>
	Epistasis
	</h3>
	is defined as the deviation from the additive expectation of allelic effects:
	$$u_{11} = w_{00} + w_{11} - (w_{01} + w_{10})$$

	<aside class="notes">
	  Mention shapes
	</aside>
</section>

<section>
	<h3>Understanding three-way interactions</h3>

	<h4>
	<p class="fragment" data-fragment-index="1">
	Marginal epistasis?
	</p>
	</h4>
	<p class="fragment" data-fragment-index="1">
	$\small u_{\color{blue}{0}11} = w_{\color{blue}{0}00} + w_{\color{blue}{1}00} + w_{\color{blue}{0}11} + w_{\color{blue}{1}11} − (w_{\color{blue}{0}01} + w_{\color{blue}{1}01}) − (w_{\color{blue}{0}10} + w_{\color{blue}{1}10})$
	</p>

	<h4>
	<p class="fragment" data-fragment-index="2">
	Total three-way interaction?
	</p>
	</h4>
	 <p class="fragment" data-fragment-index="2">
	$\small u_{111} = w_{000} + w_{011} + w_{101} + w_{110} - (w_{001} + w_{010} + w_{100} + w_{111})$
	</p>

	<h4>
	<p class="fragment" data-fragment-index="3">
	Conditional epistasis?
	<p>
	</h4>
	<p class="fragment" data-fragment-index="3">
	$\small e = w_{\color{blue}{0}00} − w_{\color{blue}{0}01} − w_{\color{blue}{0}10} + w_{\color{blue}{0}11}$
	</p>
</section>

<section>
	<h4>What if no (credible) fitness measurements are available?</h4>
	<img data-src="../talks/images/disc_diffusion.png"><br>
	<font size="2">Image: <a href="https://en.wikipedia.org/wiki/Agar_diffusion_test">Wikipedia</a></font>
</section>

<section>
	<h4>Mutation fitness graph</h4>
	<img class="stretch" data-src="../talks/images/tem.svg">
	<br>
	<font size="3">Ogbunugafor et al. <i>Malar. J.</i> 2016</font>
	</p>
</section>

<section id="rank-orders">
	<h4>Rank orders. The simplest case.</h4>
	$\small u_{11} = w_{00} + w_{11} - (w_{01} + w_{10})$<br>
	<img class="stretch" data-src="../talks/images/all_24_rankings_two_loci.svg">

	<aside class="notes">
	  Ask what colour means.
	</aside>
</section>

<section>
	<h3>Exercise: Dyck word algorithm</h3>
	<p>
	$$
	  \begin{align}
	    \small u_{011} =~
	    & w_{000} + w_{100} + w_{011} + w_{111} − \\
	    & w_{001} - w_{101} − w_{010} - w_{110}
	  \end{align}
	$$
	</p>

	<p>
	$$
	  w_{111} > w_{011} > w_{101} > w_{010} > w_{000} > w_{110} > w_{100} > w_{001}
	$$
	</p>
	<p class="fragment" data-fragment-index="1">
	$$
	  w_{111} > w_{011} > w_{100} > w_{000} > w_{001} > w_{101} > w_{010} > w_{110}
	$$
	</p>
	<p class="fragment" data-fragment-index="2">
	  A way to quantify uncertainties!
	</p>
	<p style="font-size:10pt">
	  Crona, Gavryushkin, Greene, and Beerenwinkel. Inferring genetic interactions from comparative fitness data. <i>eLife,</i> 2017.
	</p>

	<aside class="notes">
	  Game time: how do we get those rankings?
	</aside>
</section>

<section data-markdown>
<script type="text/template">
	### Numbers at a glance
	|    Loci | Imply epistasis |       Number of orders | Fraction |
	|:-------:|:---------------:|:----------------------:|:--------:|
	|    2    |      16         |          24            |   2/3    |
	|    3    |      16,128     |          40,320        |   2/5    |
	|    4    |4,649,508,864,000|  20,922,789,890,000    |   2/9    |
</script>
</section>

<section>
	<h4>Connection between rank orders and mutation graphs</h4>
	$\small u_{11} = w_{00} + w_{11} - (w_{01} + w_{10})$<br>
	<img class=stretch data-src="../talks/images/all_total_extensions_of_p_o.svg">
	<p class="fragment" data-fragment-index="1">
	  <b>Theorem.</b> A partial order (e.g. fitness graph) implies epistasis if and only if all linear extensions compatible with the partial order do.
	</p>
</section>

<section data-transition="slide-in fade-out" id="mutation-graph">
	<h4>Mutation graph</h4>
	<img class=stretch data-src="../talks/images/tem_for_Niko.svg">

	<aside class="notes">
	  Example of data science. A modern one :)
	</aside>
</section>

<section data-transition="fade-in fade-out">
	<h4>Mutation graph</h4>
	<img class=stretch data-src="../talks/images/tem_highlight_for_Niko.svg">
</section>

<section data-transition="fade-in slide-out">
	<h4>Mutation graph</h4>
	<img class=stretch data-src="../talks/images/tem_highlight_shaded.svg">
</section>

<section>
	<h4>Mutation graph</h4>
	<img class=stretch data-src="../talks/images/tem_order.svg">
</section>

<section>
	<h4>Mutation graph</h4>
	<img class=stretch data-src="../talks/images/tem_order_extension.svg"><br>
	<p style="font-size:10pt">
	  Lienkaemper, Lamberti, Drain, Beerenwinkel, and Gavryushkin. The geometry of partial fitness orders and an efficient method for detecting genetic interactions. <i>Journal of Mathematical Biology,</i> 2018.
	</p>
</section>

<section id="online-algorithms">
	<h3>4. Online algorithms to improve computational performance</h3>
	<br>
	<ul>
	  <li class="fragment" data-fragment-index="1"> The traditional way is to make the algorithm more efficient</li><br>
	  <li class="fragment" data-fragment-index="2"> When the same algorithm has to be re-run routinely, we can economise by making the algorithm slower and doing more!</li><br>
	  <li class="fragment" data-fragment-index="3"> This approach is known as online</li><br>
	</ul>
</section>

<section data-transition="slide-in fade-out">
	<h3>Online algorithms</h3>
	<img class="stretch" data-src="../talks/images/Coffee_2.svg" width="100%">
</section>

<section data-transition="fade-in fade-out">
	<h3>Online algorithms</h3>
	<img class="stretch" data-src="../talks/images/Coffee_3.svg" width="100%">
</section>

<section data-transition="fade-in fade-out">
	<h3>Online algorithms</h3>
	<img class="stretch" data-src="../talks/images/Coffee_4.svg" width="100%">
</section>

<section data-transition="fade-in slide-out">
	<h3>Online algorithms</h3>
	<img class="stretch" data-src="../talks/images/Coffee_5.svg" width="100%">
</section>

<section data-transition="slide-in fade-out">
	<h3>Online algorithms</h3>
	<img class="stretch" data-src="../talks/images/Coffee_online_1.svg" width="100%">
</section>

<section data-transition="fade-in fade-out">
	<h3>Online algorithms</h3>
	<img class="stretch" data-src="../talks/images/Coffee_online_2.svg" width="100%">
</section>

<section data-transition="fade-in fade-out">
	<h3>Online algorithms</h3>
	<img class="stretch" data-src="../talks/images/Coffee_online_3.svg" width="100%">
</section>

<section data-transition="fade-in fade-out">
	<h3>Online algorithms</h3>
	<img class="stretch" data-src="../talks/images/Coffee_online_4.svg" width="100%">
</section>

<section data-transition="fade-in slide-out">
	<h3>Online algorithms</h3>
	<img class="stretch" data-src="../talks/images/Coffee_online_5.svg" width="100%">
</section>

<section>
	<h3>Homework:</h3>
	<p style="font-size=16pm">
	  Find an efficient online algorithm to detect genetic interactions from
	<ul>
	  <li> <a href="#/rank-orders">rank orders of genotypes</a>
	  <li> <a href="#/mutation-graph">partial orders of genotypes</a>
	</ul>
	</p>
</section>

</div>
</div>

<script src="../talks/lib/js/head.min.js"></script>
<script src="../talks/js/reveal.js"></script>
<script>
  Reveal.initialize({
    dependencies: [
	// Speaker notes
	{ src: '../talks/plugin/notes/notes.js', async: true },
        // Interpret Markdown in <section> elements
        { src: '../talks/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        { src: '../talks/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        // MathJax
        { src: '../talks/plugin/math/math.js', async: true }
    ]
  });
  Reveal.configure({ slideNumber: true });
</script>

<script>
	var link = document.createElement( 'link' );
	link.rel = 'stylesheet';
	link.type = 'text/css';
	link.href = window.location.search.match( /print-pdf/gi ) ? '../talks/css/print/pdf.css' : '..talks/css/print/paper.css';
	document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-86783531-1', 'auto');
  ga('send', 'pageview');
</script>
</body>
</html>
